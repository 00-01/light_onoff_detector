{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from datetime import datetime as dt\n",
    "import csv, os, glob\n",
    "from pprint import pprint\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "# from sklearn.preprocessing import label_binarize\n",
    "from scipy import interp\n",
    "\n",
    "import tensorflow.keras as k\n",
    "from tensorflow.math import confusion_matrix\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import keras_tuner as kt\n",
    "\n",
    "# load tensorboard\n",
    "%load_ext tensorboard"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def draw_CM(label, predicted):\n",
    "    cm = confusion_matrix(label, predicted)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    # true : false rate\n",
    "    true = 0\n",
    "    false = 0\n",
    "    for i, j in enumerate(label):\n",
    "        if j != predicted[i]:\n",
    "            false += 1\n",
    "        else: true += 1\n",
    "\n",
    "    classification_report = metrics.classification_report(label, predicted)\n",
    "    multilabel_to_binary_matrics = metrics.multilabel_confusion_matrix(label, predicted)\n",
    "\n",
    "    return plt.show(), print('true rate: ', true), print('false rate: ', false), print(), print('='*10, 'classification_report: ', '\\n', classification_report), print('='*10, 'multilabel_to_binary_matrics by class_num: ','\\n','[[TN / FP] [FN / TP]]','\\n', multilabel_to_binary_matrics)\n",
    "    \n",
    "def draw_ROC_AUC(x, y, category_names):\n",
    "    n_classes = len(category_names)\n",
    "\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y[:, i], x[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y.ravel(), x.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "            label=f'micro-average ROC curve (area = {roc_auc[\"micro\"]:0.2f})', \n",
    "            color='deeppink', linestyle=':', linewidth=1)\n",
    "\n",
    "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "            label=f'macro-average ROC curve (area = {roc_auc[\"macro\"]:0.2f})',\n",
    "            color='navy', linestyle=':', linewidth=1)\n",
    "\n",
    "    colors = (['purple', 'pink', 'red', 'green', 'yellow', 'cyan', 'magenta', 'blue'])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=1, label=f'Class {i} ROC curve (area = {roc_auc[i]:0.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "    plt.xlim([-.01, 1.0])\n",
    "    plt.ylim([0.0, 1.01])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC & AUC')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    return plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# retrain\n",
    "model_name = \"model/model_\"\n",
    "model = k.models.load_model(model_name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "path = '/home/z/data/label/'\n",
    "for file in glob.glob(path + \"*.csv\"):\n",
    "    df = pd.read_csv(file)\n",
    "    df = df[['device_field03', 'illuminance_onoff', 'device_data_reg_dtm']]\n",
    "    light_data = df['device_field03']\n",
    "    label_data = df['illuminance_onoff']\n",
    "    time_data = df['device_data_reg_dtm']\n",
    "    start = 230\n",
    "    end = 245\n",
    "\n",
    "    print(light_data.shape)\n",
    "    print(label_data.shape)\n",
    "    print(df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def to_sequences(seq_size, t1, t2):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(len(t1)-seq_size):\n",
    "        ta1 = t1[i:(i+seq_size)]\n",
    "        ta2 = t2[i-1+seq_size]\n",
    "        # ta1 = [[x] for x in ta1]\n",
    "        x.append(ta1)\n",
    "        y.append(ta2)\n",
    "        \n",
    "    return np.array(x), np.array(y) \n",
    "\n",
    "timesteps = 6\n",
    "x_train, y_train = to_sequences(timesteps,train_data, train_label)\n",
    "x_test, y_test = to_sequences(timesteps,test_data, test_label)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(x_test[start:end])\n",
    "print(y_test[start:end])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "print(x_train[100:105])\n",
    "print(y_train[100:105])\n",
    "print(x_test[100:105])\n",
    "print(y_test[100:105])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# # plot\n",
    "# fig = px.line(df, x='device_data_reg_dtm', y=['device_field03', 'illuminance_onoff'])\n",
    "# fig.update_xaxes(rangeslider_visible=True)\n",
    "# fig.show(renderer='browser')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "loss, acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "# print(f'test_loss: {loss} test_accuracy: {acc}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predict = model.predict(x_test)\n",
    "predicted = np.argmax(predict, axis=1)\n",
    "y1 = np.argmax(y_test, axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(y1[:100])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# CM\n",
    "draw_CM(y1, predicted)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ROC, AUC\n",
    "draw_ROC_AUC(predict, y_test, classes)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# # launch tensorboard @ localhost:6006\n",
    "# %tensorboard --logdir logs/ --host localhost --port 6006"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# df.to_csv(\"data.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}